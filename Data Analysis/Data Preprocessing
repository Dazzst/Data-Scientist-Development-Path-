```markdown
# 数据预处理 (Data Preprocessing)

数据预处理是数据分析和机器学习流程中至关重要的一步，旨在提高数据质量和模型性能。

## （一）数据清洗的重点处理数据

在进行数据清洗时，重点处理以下几类数据：

1.  **缺失值 (Missing Values)：**
    * **描述：** 数据集中缺少应有的值。
    * **处理方法：** 填充（均值、中位数、众数、模型预测），或直接删除缺失值所在的行/列。

2.  **异常值 (Outliers)：**
    * **描述：** 严重偏离其他观测值的样本点。
    * **处理方法：** 统计方法（如 $3\sigma$ 原则、IQR）、可视化分析（如箱线图）、**封顶和封底 (Capping and Flooring)**、或单独分组分析。

3.  **重复值 (Duplicate Values)：**
    * **描述：** 数据集中存在完全相同或部分相同的记录。
    * **处理方法：** 识别并删除重复的行。

4.  **格式错误 (Format Errors)：**
    * **描述：** 数据类型、编码、日期等格式不符合要求。
    * **处理方法：** 强制类型转换（如日期格式统一）、文本清理。

5.  **不一致的数据 (Inconsistent Data)：**
    * **描述：** 同一实体或概念有多种表示（如大小写不一、单位不统一）。
    * **处理方法：** 统一命名规则、单位转换。

## （二）扩展重点关注的数据问题

除了基础五类，高质量的数据清洗还需关注：

1.  **数据类型不匹配 (Schema Mismatch)：**
    * **描述：** 列的实际存储类型与预期不一致（例如，数值存储为字符串）。
    * **处理方法：** 强制类型转换，例如将数值列从 `string` 转换为 `float`。

2.  **数据逻辑错误 (Logical Errors)：**
    * **描述：** 数据在业务或逻辑上不合理（例如，年龄为负数、订单完成时间早于下单时间）。
    * **处理方法：** 设定业务约束进行校验，标记或修正。

3.  **冗余特征 (Redundant Features)：**
    * **描述：** 数据集中存在高度相关或信息重复的特征列。
    * **处理方法：** **相关性分析**、**特征选择**、**主成分分析 (PCA)** 进行特征降维。

## （三）数据清洗与预处理的详细流程

以下流程在传统清洗流程上增加了数据质量和模型准备步骤，使其更加严谨完整：

1.  **数据导入：** 将原始数据导入工作环境。

2.  **观察和初步分析 & 数据质量报告生成：**
    * 查看数据结构 (`shape`, `dtype`, 统计描述)。
    * 生成详细报告，量化缺失值比例、异常值分布、重复值数量等，建立清洗基线。

3.  **处理缺失值：**
    * 根据数据特性选择策略：**均值/中位数/众数填充**（随机缺失）、**前一个/后一个观测值填充 (LOCF/NOCF)**（时间序列）、或**模型预测填充**（非随机缺失）。

4.  **处理异常值：**
    * 识别并处理。可采用**删除**、**替换（封顶和封底）**或**单独分组**。

5.  **处理重复值、格式错误和不一致数据：** 统一清理数据。

6.  **数据标准化/归一化：**
    * **目的：** 为后续机器学习模型训练做准备。
    * **方法：** **Min-Max 归一化**（缩放到 $[0, 1]$ 范围）或 **Z-Score 标准化**（转换为 $\mu=0, \sigma=1$）。

7.  **特征工程 (Feature Engineering)：**
    * **目的：** 基于现有数据创建新的、更有意义的特征。
    * **方法：** 从日期时间中提取年/月/日/星期几；对分类特征进行 **One-Hot 编码**或**标签编码**；对数值特征进行分箱。

8.  **数据导出：** 将清洗、转换后的数据导出，供模型训练或进一步分析使用。
```
